{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "doNFRjPqiBhM",
    "colab_type": "code",
    "outputId": "fe7e0af0-8d91-45bb-d819-c3cc1b3e11a4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  uncased_L-12_H-768_A-12.zip\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
     ]
    }
   ],
   "source": [
    "# @title Preparation\n",
    "!pip install -q keras-bert\n",
    "!wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!unzip -o uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KUQ8UtquieFj",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# @title Environment\n",
    "import os\n",
    "\n",
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "\n",
    "# TF_KERAS must be added to environment variables in order to use TPU\n",
    "os.environ['TF_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sVTPNxOyj4HJ",
    "colab_type": "code",
    "outputId": "570fdbc8-699f-4dd1-d5cf-b1b930c0b714",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# @title Load Basic Model\n",
    "import codecs\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "\n",
    "token_dict = {}\n",
    "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "\n",
    "model = load_trained_model_from_checkpoint(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    training=True,\n",
    "    trainable=False,\n",
    "    seq_len=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OhMA1j7wnqSm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# @title Build Custom Model\n",
    "from tensorflow.python import keras\n",
    "from keras_bert.optimizers import AdamWarmup\n",
    "\n",
    "inputs = model.inputs[:2]\n",
    "dense = model.get_layer('NSP-Dense').output\n",
    "outputs = keras.layers.Dense(units=2, activation='softmax')(dense)\n",
    "\n",
    "model = keras.models.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    AdamWarmup(decay_steps=100000, warmup_steps=1000),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_d16-VGMnrj3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# @title Initialize Variables\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "sess = K.get_session()\n",
    "uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
    "init_op = tf.variables_initializer(\n",
    "    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
    ")\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gTt2Z2rKkZ4-",
    "colab_type": "code",
    "outputId": "fd2c4730-8bd3-42cb-cf0b-c064de524881",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Querying Tensorflow master (grpc://10.12.162.170:8470) for TPU system metadata.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 9447741190219693902)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17426934761049643520)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12836661232812106036)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 9004002198568460939)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3620266159979408089)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 606180581882991905)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 16717205192285078985)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 16978462502564682025)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4000316900367590404)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5435378045325686618)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 3359629665181307472)\n",
      "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Cloning AdamWarmup {'decay_steps': 100000.0, 'warmup_steps': 1000.0, 'min_lr': 0.0, 'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'epsilon': 1e-07, 'weight_decay': 0.0, 'weight_decay_pattern': None, 'amsgrad': False}\n",
      "INFO:tensorflow:Cloning AdamWarmup {'decay_steps': 100000.0, 'warmup_steps': 1000.0, 'min_lr': 0.0, 'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'epsilon': 1e-07, 'weight_decay': 0.0, 'weight_decay_pattern': None, 'amsgrad': False}\n"
     ]
    }
   ],
   "source": [
    "# @title Convert to TPU Model\n",
    "import tensorflow as tf\n",
    "from keras_bert import get_custom_objects\n",
    "\n",
    "tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "strategy = tf.contrib.tpu.TPUDistributionStrategy(\n",
    "    tf.contrib.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
    ")\n",
    "\n",
    "with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
    "    tpu_model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xioN-O_vtztC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# @title Download IMDB Data\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    fname=\"aclImdb.tar.gz\", \n",
    "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "    extract=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xfC3Nh8pnckd",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85.0
    },
    "outputId": "69a882d3-312a-42a0-defb-a96ad52c2d3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:45<00:00, 271.86it/s]\n",
      "100%|██████████| 12500/12500 [00:47<00:00, 261.77it/s]\n",
      "100%|██████████| 12500/12500 [00:45<00:00, 272.46it/s]\n",
      "100%|██████████| 12500/12500 [00:46<00:00, 270.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# @title Convert Data to Array\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras_bert import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(token_dict)\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    global tokenizer\n",
    "    indices, sentiments = [], []\n",
    "    for folder, sentiment in (('neg', 0), ('pos', 1)):\n",
    "        folder = os.path.join(path, folder)\n",
    "        for name in tqdm(os.listdir(folder)):\n",
    "            with open(os.path.join(folder, name), 'r') as reader:\n",
    "                  text = reader.read()\n",
    "            ids, segments = tokenizer.encode(text, max_len=300)\n",
    "            indices.append(ids)\n",
    "            sentiments.append(sentiment)\n",
    "    items = list(zip(indices, sentiments))\n",
    "    np.random.shuffle(items)\n",
    "    indices, sentiments = zip(*items)\n",
    "    indices = np.array(indices)\n",
    "    return [indices, np.zeros_like(indices)], np.array(sentiments)\n",
    "  \n",
    "  \n",
    "  \n",
    "train_path = os.path.join(os.path.dirname(dataset), 'aclImdb', 'train')\n",
    "test_path = os.path.join(os.path.dirname(dataset), 'aclImdb', 'test')\n",
    "\n",
    "\n",
    "train_x, train_y = load_data(train_path)\n",
    "test_x, test_y = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QgP7bCQxrZpQ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357.0
    },
    "outputId": "d924999b-3449-47de-a063-8dfff5b35f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 46s 2ms/sample - loss: 0.4440 - sparse_categorical_accuracy: 0.7949\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 46s 2ms/sample - loss: 0.4345 - sparse_categorical_accuracy: 0.8042\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 46s 2ms/sample - loss: 0.4354 - sparse_categorical_accuracy: 0.8007\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 46s 2ms/sample - loss: 0.4286 - sparse_categorical_accuracy: 0.8058\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 45s 2ms/sample - loss: 0.4240 - sparse_categorical_accuracy: 0.8058\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 46s 2ms/sample - loss: 0.4244 - sparse_categorical_accuracy: 0.8056\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 45s 2ms/sample - loss: 0.4234 - sparse_categorical_accuracy: 0.8069\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 46s 2ms/sample - loss: 0.4193 - sparse_categorical_accuracy: 0.8115\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 46s 2ms/sample - loss: 0.4190 - sparse_categorical_accuracy: 0.8106\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 46s 2ms/sample - loss: 0.4158 - sparse_categorical_accuracy: 0.8140\n"
     ]
    }
   ],
   "source": [
    "# @title Fit\n",
    "\n",
    "with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
    "    tpu_model.fit(train_x, train_y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZBSba3vprlRD",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "465b7816-cc03-4965-d735-d09d9468ea47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 37s 1ms/sample\n"
     ]
    }
   ],
   "source": [
    "# @title Predict\n",
    "\n",
    "with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
    "    predicts = tpu_model.predict(test_x, verbose=True).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Wo1aps8prrCq",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "906c6277-10ee-45b6-8263-77156c65ea4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82036\n"
     ]
    }
   ],
   "source": [
    "# @title Accuracy\n",
    "\n",
    "print(np.sum(test_y == predicts) / test_y.shape[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "keras_bert_load_and_fit_tpu.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
